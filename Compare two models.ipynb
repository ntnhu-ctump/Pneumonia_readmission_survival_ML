{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58da8b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, brier_score_loss,\n",
    "    roc_curve, precision_recall_curve\n",
    ")\n",
    "\n",
    "A_PATH = Path(\"modelA_preds.csv\")\n",
    "B_PATH = Path(\"modelB_preds.csv\")\n",
    "THRESH = 0.50  \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "_EPS = 1e-9\n",
    "\n",
    "def _expit(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def _logit(p):\n",
    "    p = np.clip(np.asarray(p, float), _EPS, 1.0 - _EPS)\n",
    "    return np.log(p / (1.0 - p))\n",
    "\n",
    "def ci_logit_percentile_01(x, lo=2.5, hi=97.5):\n",
    "    z = _logit(np.clip(np.asarray(x, float), _EPS, 1.0 - _EPS))\n",
    "    lz, hz = np.nanpercentile(z, [lo, hi])\n",
    "    return float(_expit(lz)), float(_expit(hz))\n",
    "\n",
    "def ci_logit_percentile_diff01(x, lo=2.5, hi=97.5):\n",
    "    x = np.asarray(x, float)\n",
    "    z01 = (np.clip(x, -1.0 + _EPS, 1.0 - _EPS) + 1.0) / 2.0\n",
    "    lo01, hi01 = ci_logit_percentile_01(z01, lo=lo, hi=hi)\n",
    "    return 2.0 * lo01 - 1.0, 2.0 * hi01 - 1.0\n",
    "\n",
    "def _pick_col(df, candidates, required=False, name=\"\"):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    if required:\n",
    "        raise ValueError(f\"Missing required column for {name}. Tried {candidates}\")\n",
    "    return None\n",
    "\n",
    "def load_preds(path: Path, tag: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, dtype={\"SEQN\":\"string\",\"SDMVPSU\":\"string\",\"SDMVSTRA\":\"string\"})\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    c_id = _pick_col(df, [\"SEQN\",\"seqn\"], True, \"SEQN\")\n",
    "    c_y  = _pick_col(df, [\"y\",\"y2\",\"Y\"], True, \"outcome\")\n",
    "    c_p  = _pick_col(df, [\"p\",\"p_cal\",\"p2\",\"p_uncal\"], True, \"probability\")\n",
    "    c_w  = _pick_col(df, [\"w\",\"w2\"], False, \"weight\")\n",
    "\n",
    "    keep = {c_id:\"SEQN\", c_y:f\"y_{tag}\", c_p:f\"p_{tag}\"}\n",
    "    if c_w: keep[c_w] = f\"w_{tag}\"\n",
    "    if \"SDMVPSU\" in df.columns: keep[\"SDMVPSU\"] = f\"SDMVPSU_{tag}\"\n",
    "    if \"SDMVSTRA\" in df.columns: keep[\"SDMVSTRA\"] = f\"SDMVSTRA_{tag}\"\n",
    "\n",
    "    return df[list(keep.keys())].rename(columns=keep).reset_index(drop=True)\n",
    "\n",
    "A = load_preds(A_PATH, \"A\")\n",
    "B = load_preds(B_PATH, \"B\")\n",
    "\n",
    "M = A.merge(B, on=\"SEQN\", how=\"inner\", validate=\"one_to_one\", suffixes=(\"_A\",\"_B\"))\n",
    "\n",
    "def coalesce_design(df: pd.DataFrame, base: str) -> pd.DataFrame:\n",
    "    a, b = f\"{base}_A\", f\"{base}_B\"\n",
    "    if base in df.columns: return df\n",
    "    has_a, has_b = a in df.columns, b in df.columns\n",
    "    if not (has_a or has_b): return df\n",
    "    if has_a and has_b:\n",
    "        same = (df[a].fillna(\"\").astype(str) == df[b].fillna(\"\").astype(str))\n",
    "        if not bool(same.all()):\n",
    "            print(f\"WARNING: {base}_A and {base}_B differ; using {a}.\")\n",
    "        df[base] = df[a]\n",
    "    else:\n",
    "        df[base] = df[a] if has_a else df[b]\n",
    "    return df\n",
    "\n",
    "M = coalesce_design(M, \"SDMVPSU\")\n",
    "M = coalesce_design(M, \"SDMVSTRA\")\n",
    "\n",
    "y = M[\"y_A\"].to_numpy(int)\n",
    "if not np.array_equal(M[\"y_A\"].to_numpy(), M[\"y_B\"].to_numpy()):\n",
    "    raise RuntimeError(\"Outcome mismatch between filesâ€”ensure same test cohort & labels.\")\n",
    "\n",
    "pA = M[\"p_A\"].to_numpy(float)\n",
    "pB = M[\"p_B\"].to_numpy(float)\n",
    "\n",
    "if \"w_A\" in M.columns and \"w_B\" in M.columns and np.allclose(M[\"w_A\"], M[\"w_B\"], equal_nan=True):\n",
    "    w = M[\"w_A\"].fillna(0.0).to_numpy(float)\n",
    "elif \"w_A\" in M.columns:\n",
    "    w = M[\"w_A\"].fillna(0.0).to_numpy(float)\n",
    "elif \"w_B\" in M.columns:\n",
    "    w = M[\"w_B\"].fillna(0.0).to_numpy(float)\n",
    "else:\n",
    "    w = np.ones(len(M), dtype=float)\n",
    "\n",
    "psu  = M[\"SDMVPSU\"].astype(str).to_numpy()  if \"SDMVPSU\"  in M.columns else None\n",
    "stra = M[\"SDMVSTRA\"].astype(str).to_numpy() if \"SDMVSTRA\" in M.columns else None\n",
    "\n",
    "\n",
    "def metrics_w(y, p, w):\n",
    "    auc = roc_auc_score(y, p, sample_weight=w)\n",
    "    ap  = average_precision_score(y, p, sample_weight=w)\n",
    "    b   = brier_score_loss(y, p, sample_weight=w)\n",
    "    return auc, ap, b\n",
    "\n",
    "def confusion_at(y, p, w, thr):\n",
    "    yhat = (p >= thr).astype(int)\n",
    "    pos = (y == 1); neg = ~pos\n",
    "    tp = float(np.sum(w[(yhat==1) & pos])); fn = float(np.sum(w[(yhat==0) & pos]))\n",
    "    tn = float(np.sum(w[(yhat==0) & neg])); fp = float(np.sum(w[(yhat==1) & neg]))\n",
    "    sens = tp/(tp+fn) if tp+fn>0 else np.nan\n",
    "    spec = tn/(tn+fp) if tn+fp>0 else np.nan\n",
    "    ppv  = tp/(tp+fp) if tp+fp>0 else np.nan\n",
    "    npv  = tn/(tn+fn) if tn+fn>0 else np.nan\n",
    "    return sens, spec, ppv, npv\n",
    "\n",
    "aucA, apA, bA = metrics_w(y, pA, w)\n",
    "aucB, apB, bB = metrics_w(y, pB, w)\n",
    "\n",
    "print(\"=== Point estimates (weighted) ===\")\n",
    "print(f\"Model A: AUC={aucA:.3f} | PR-AUC={apA:.3f} | Brier={bA:.3f}\")\n",
    "print(f\"Model B: AUC={aucB:.3f} | PR-AUC={apB:.3f} | Brier={bB:.3f}\")\n",
    "\n",
    "\n",
    "def pr_baseline(y, w):\n",
    "    tot = np.sum(w)\n",
    "    return float(np.sum(w[y==1]) / tot) if tot > 0 else 0.0  \n",
    "\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "for p, name in [(pA,\"A\"), (pB,\"B\")]:\n",
    "    fpr, tpr, _ = roc_curve(y, p, sample_weight=w)\n",
    "    auc = roc_auc_score(y, p, sample_weight=w)\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC={auc:.3f})\")\n",
    "plt.plot([0,1],[0,1], \"--\", alpha=0.6)\n",
    "plt.xlabel(\"1 - Specificity\"); plt.ylabel(\"Sensitivity\"); plt.title(\"TEST ROC (weighted)\")\n",
    "plt.legend(); plt.tight_layout(); plt.savefig(\"compare_roc.png\", dpi=150)\n",
    "\n",
    "\n",
    "prev = pr_baseline(y, w)\n",
    "plt.figure(figsize=(7,6))\n",
    "for p, name in [(pA,\"A\"), (pB,\"B\")]:\n",
    "    prec, rec, _ = precision_recall_curve(y, p, sample_weight=w)\n",
    "    ap = average_precision_score(y, p, sample_weight=w)\n",
    "    plt.plot(rec, prec, label=f\"{name} (AP={ap:.3f})\")\n",
    "plt.axhline(prev, linestyle=\"--\", alpha=0.7, label=f\"Baseline (prev={prev:.3f})\")\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"TEST PR (weighted)\")\n",
    "plt.legend(); plt.tight_layout(); plt.savefig(\"compare_pr.png\", dpi=150)\n",
    "\n",
    "def _weighted_quantile(x, w, q):\n",
    "    order = np.argsort(x); xs, ws = x[order], w[order]\n",
    "    cdf = np.cumsum(ws)/np.sum(ws)\n",
    "    return np.interp(q, cdf, xs)\n",
    "\n",
    "def weighted_calibration_curve(y, p, w, n_bins=10, strategy=\"quantile\"):\n",
    "    y, p, w = y.astype(int), p.astype(float), np.clip(w.astype(float), 0.0, np.inf)\n",
    "    if strategy == \"quantile\":\n",
    "        edges = _weighted_quantile(p, w, np.linspace(0,1,n_bins+1))\n",
    "        edges[0], edges[-1] = 0.0, 1.0\n",
    "    else:\n",
    "        edges = np.linspace(0,1,n_bins+1)\n",
    "    edges = np.unique(edges)\n",
    "    idx = np.digitize(p, edges[1:-1], right=False)\n",
    "    pm, tm, bw = [], [], []\n",
    "    for b in range(len(edges)-1):\n",
    "        m = (idx == b); wb = w[m]\n",
    "        if wb.sum() <= 0: continue\n",
    "        pm.append(np.average(p[m], weights=wb))\n",
    "        tm.append(np.average(y[m], weights=wb))\n",
    "        bw.append(wb.sum())\n",
    "    return np.array(pm), np.array(tm), edges, np.array(bw)\n",
    "\n",
    "def weighted_ece(y, p, w, n_bins=10):\n",
    "    pm, tm, _, bw = weighted_calibration_curve(y, p, w, n_bins=n_bins)\n",
    "    if bw.sum() == 0 or len(bw) == 0: return np.nan\n",
    "    return float(np.sum((bw / bw.sum()) * np.abs(tm - pm)))\n",
    "\n",
    "eceA = weighted_ece(y, pA, w, n_bins=10)\n",
    "eceB = weighted_ece(y, pB, w, n_bins=10)\n",
    "pmA, tmA, _, _ = weighted_calibration_curve(y, pA, w, n_bins=10)\n",
    "pmB, tmB, _, _ = weighted_calibration_curve(y, pB, w, n_bins=10)\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.plot([0,1],[0,1], \"--\", lw=1, label=\"Perfect\")\n",
    "plt.plot(pmA, tmA, \"o-\", label=f\"A (ECE={eceA:.3f}, Brier={bA:.3f})\")\n",
    "plt.plot(pmB, tmB, \"o-\", label=f\"B (ECE={eceB:.3f}, Brier={bB:.3f})\")\n",
    "plt.xlabel(\"Mean predicted probability\"); plt.ylabel(\"Observed positive fraction\")\n",
    "plt.title(\"TEST Calibration (weighted)\"); plt.legend(); plt.tight_layout()\n",
    "plt.savefig(\"compare_calibration.png\", dpi=150)\n",
    "\n",
    "def reclass_table(y, p_old, p_new, w, thr):\n",
    "    a = (p_old >= thr).astype(int)\n",
    "    b = (p_new >= thr).astype(int)\n",
    "    def wsum(mask): return float(np.sum(w[mask]))\n",
    "    tbl = pd.DataFrame({\n",
    "        \"down\": [wsum((a==1)&(b==0)&(y==1)), wsum((a==1)&(b==0)&(y==0))],\n",
    "        \"stay\": [wsum((a==1)&(b==1)&(y==1))+wsum((a==0)&(b==0)&(y==1)),\n",
    "                 wsum((a==1)&(b==1)&(y==0))+wsum((a==0)&(b==0)&(y==0))],\n",
    "        \"up\":   [wsum((a==0)&(b==1)&(y==1)), wsum((a==0)&(b==1)&(y==0))]\n",
    "    }, index=[\"event\",\"nonevent\"])\n",
    "    w_event = float(np.sum(w[y==1])); w_none = float(np.sum(w[y==0]))\n",
    "    p_up_e   = tbl.loc[\"event\",\"up\"]   / w_event if w_event>0 else np.nan\n",
    "    p_down_e = tbl.loc[\"event\",\"down\"] / w_event if w_event>0 else np.nan\n",
    "    p_up_ne  = tbl.loc[\"nonevent\",\"up\"]/ w_none  if w_none>0 else np.nan\n",
    "    p_down_ne= tbl.loc[\"nonevent\",\"down\"]/w_none if w_none>0 else np.nan\n",
    "    nri = (p_up_e - p_down_e) + (p_down_ne - p_up_ne)\n",
    "    return tbl, nri\n",
    "\n",
    "tbl, nri = reclass_table(y, pA, pB, w, THRESH)\n",
    "print(f\"\\n=== Weighted reclassification at thr={THRESH:.3f} (A -> B) ===\")\n",
    "print(tbl)\n",
    "print(f\"NRI (category-free at this thr): {nri:.3f}\")\n",
    "\n",
    "labels = [\"Î”AUC (Bâˆ’A)\",\"Î”PR-AUC\",\"Î”Brier\",\"Î”Sens\",\"Î”Spec\",\"Î”PPV\",\"Î”NPV\"]\n",
    "\n",
    "def diff_metrics(y, pA, pB, w, thr):\n",
    "    d_auc = roc_auc_score(y, pB, sample_weight=w) - roc_auc_score(y, pA, sample_weight=w)\n",
    "    d_ap  = average_precision_score(y, pB, sample_weight=w) - average_precision_score(y, pA, sample_weight=w)\n",
    "    d_br  = brier_score_loss(y, pB, sample_weight=w) - brier_score_loss(y, pA, sample_weight=w)\n",
    "    sA, cA, ppvA, npvA = confusion_at(y, pA, w, thr)\n",
    "    sB, cB, ppvB, npvB = confusion_at(y, pB, w, thr)\n",
    "    return np.array([d_auc, d_ap, d_br, (sB-sA), (cB-cA), (ppvB-ppvA), (npvB-npvA)], dtype=float)\n",
    "\n",
    "def psu_bootstrap_within_strata(psu_ids, strata_ids, B=1000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    u_strata = np.unique(strata_ids)\n",
    "    n = len(psu_ids)\n",
    "    for _ in range(B):\n",
    "        mult = np.zeros(n, dtype=float)\n",
    "        for s in u_strata:\n",
    "            m = (strata_ids == s)\n",
    "            psu_s = np.unique(psu_ids[m])\n",
    "            draw = rng.choice(psu_s, size=len(psu_s), replace=True)\n",
    "            counts = pd.Series(draw).value_counts()\n",
    "            mult[m] = [counts.get(pid, 0) for pid in psu_ids[m]]\n",
    "        yield mult\n",
    "\n",
    "def psu_bootstrap_unstratified(psu_ids, B=1000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    u = np.unique(psu_ids)\n",
    "    for _ in range(B):\n",
    "        draw = rng.choice(u, size=len(u), replace=True)\n",
    "        counts = pd.Series(draw).value_counts()\n",
    "        yield np.array([counts.get(pid, 0) for pid in psu_ids], dtype=float)\n",
    "\n",
    "if (psu is not None) and (stra is not None):\n",
    "    n_per_stratum = M.groupby(\"SDMVSTRA\")[\"SDMVPSU\"].nunique()\n",
    "    strat_ok = bool((n_per_stratum >= 2).all())\n",
    "    if strat_ok:\n",
    "        gen = psu_bootstrap_within_strata(psu, stra, B=1000, seed=42)\n",
    "    else:\n",
    "        print(\"\\nWARNING: Test set has 'lonely PSUs' (some strata with only 1 PSU).\")\n",
    "        print(\"Using UNSTRATIFIED PSU bootstrap for CIs (design-inconsistent).\")\n",
    "        gen = psu_bootstrap_unstratified(psu, B=1000, seed=42)\n",
    "\n",
    "    diffs_collect = []\n",
    "    reps_used = 0\n",
    "    for mult in gen:\n",
    "        wb = w * mult\n",
    "        if wb.sum() <= 0:\n",
    "            continue\n",
    "        if (np.sum(wb[y==1]) == 0) or (np.sum(wb[y==0]) == 0):\n",
    "            continue\n",
    "        diffs_collect.append(diff_metrics(y, pA, pB, wb, THRESH))\n",
    "        reps_used += 1\n",
    "\n",
    "    diffs_collect = np.asarray(diffs_collect, float)\n",
    "    print(\"\\n=== PSU-bootstrap 95% CIs for metric differences (B âˆ’ A) â€” logit-percentile ===\")\n",
    "    print(f\"Bootstrap replicates used: {reps_used}\")\n",
    "    point = diff_metrics(y, pA, pB, w, THRESH)\n",
    "\n",
    "    for i, lab in enumerate(labels):\n",
    "        lo, hi = ci_logit_percentile_diff01(diffs_collect[:, i])  \n",
    "        print(f\"{lab}: point={point[i]:.4f} | 95% CI [{lo:.4f}, {hi:.4f}]\")\n",
    "else:\n",
    "    print(\"\\nDesign IDs missing (SDMVPSU/SDMVSTRA). Skipping design-based CIs.\")\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(pA, pB, s=8, alpha=0.25)\n",
    "plt.plot([0,1],[0,1], \"--\", alpha=0.5)\n",
    "plt.xlabel(\"p(A)\"); plt.ylabel(\"p(B)\"); plt.title(\"Predicted probabilities: Model A vs B\")\n",
    "plt.tight_layout(); plt.savefig(\"compare_scatter_pA_pB.png\", dpi=150)\n",
    "-\n",
    "summary_df = pd.DataFrame({\n",
    "    \"metric\": [\"AUC\",\"PR-AUC\",\"Brier\"],\n",
    "    \"Model_A\": [aucA, apA, bA],\n",
    "    \"Model_B\": [aucB, apB, bB],\n",
    "    \"Diff_B_minus_A\": [aucB-aucA, apB-apA, bB-bA]\n",
    "})\n",
    "summary_df.to_csv(\"compare_summary.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved: compare_roc.png, compare_pr.png, compare_calibration.png, compare_scatter_pA_pB.png, compare_summary.csv\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
